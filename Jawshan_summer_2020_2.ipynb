{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jawshan_summer_2020_2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbnyeJe/B56cp7RE7MsbC4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jawshan/CompNeuro_Summer2020/blob/master/Jawshan_summer_2020_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eGwgpvgOKd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Data retrival\n",
        "import os, requests\n",
        "\n",
        "fname = []\n",
        "for j in range(3):\n",
        "  fname.append('steinmetz_part%d.npz'%j)\n",
        "url = [\"https://osf.io/agvxh/download\"]\n",
        "url.append(\"https://osf.io/uv3mw/download\")\n",
        "url.append(\"https://osf.io/ehmw2/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1kP4ZudPrOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Import matplotlib and set defaults\n",
        "from matplotlib import rcParams \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] =15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLdP1L-pP5-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Data loading\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "alldat = np.array([])\n",
        "for j in range(len(fname)):\n",
        "    alldat = np.hstack((alldat, np.load('steinmetz_part%d.npz'%j, allow_pickle=True)['dat']))\n",
        "dat = alldat[11]"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0owOPvcQfqYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Data Extraction\n",
        "def extract_data(data, brain_area):\n",
        "  row = {}\n",
        "  row['mouse_name']     = data['mouse_name']\n",
        "  row['num_v1_neurons'] = np.sum(data['brain_area']=='VISp')\n",
        "  row['num_neurons'], row['num_trials'], row['num_time_bins'] = data['spks'].shape\n",
        "  row['start_time']      = 0.0\n",
        "  row['stim_onset_time'] = data['stim_onset']\n",
        "  row['gocue_time']      = data['gocue']\n",
        "  row['response_time']   = data['response_time']\n",
        "  row['feedback_time']   = data['feedback_time']\n",
        "  row['end_time']        = data['bin_size'] * row['num_time_bins']\n",
        "  row['contrast_right'] = data['contrast_right']\n",
        "  row['contrast_left']  = data['contrast_left']\n",
        "  # feedback (-ve,+ve)          :  âˆˆ {-1,1}  \n",
        "  row['response']        = data['response']\n",
        "  row['feedback']        = data['feedback_type']\n",
        "  row['binary_feedback'] = np.array(data['feedback_type'] == 1).astype(int)\n",
        "  ## Extracting spikes from neurons corresponding to specified region\n",
        "  visp_indexes = np.argwhere(data['brain_area']==brain_area)\n",
        "  reduced_neuron_spikes = np.squeeze(data['spks'][visp_indexes,:,:],1)  \n",
        "  ## Reshaping spikes to have trials dimension first : #trials, #neurons, #time_bins \n",
        "  row['spikes'] = reduced_neuron_spikes.transpose(1,0,2)\n",
        "  ## Convert spikes to time & spike count per trial\n",
        "  row['spike_times'] = np.zeros_like(row['spikes']).astype(np.float16)\n",
        "  ax1, ax2, ax3      = np.shape(row['spikes'])\n",
        "  row['spike_count'] = np.zeros((ax1, ax2, 1)).astype(np.float16)\n",
        "  correction         = 1/1000\n",
        "  for i, trial in enumerate(row['spike_times']):\n",
        "    for j, neuron in enumerate(row['spike_times'][i]):\n",
        "      row['spike_count'][i][j] = np.sum(row['spikes'][i][j])\n",
        "      spike_time_list          = [10 * bin if spike !=0 else 0 for bin, spike in enumerate(row['spikes'][i][j])]\n",
        "      row['spike_times'][i][j] = np.array(spike_time_list).astype(np.float16)\n",
        "  row['spikes_reordered'] = reduced_neuron_spikes\n",
        "  return(row)\n",
        "extracted_data = np.array(list(map(lambda data: extract_data(data, 'VISp'), alldat)))\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjNHCNALgFEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "8763618a-9a21-4a05-ebae-92e4f6eb5e3c"
      },
      "source": [
        "#@title Data Table\n",
        "time_cols = ['start_time','stim_onset_time','gocue_time','response_time','feedback_time','end_time']\n",
        "id_cols  = ['mouse_name']\n",
        "dim_cols = ['num_v1_neurons','num_neurons','num_trials','num_time_bins','spike_times']\n",
        "\n",
        "cols = id_cols + dim_cols\n",
        "\n",
        "df = pd.DataFrame.from_records(extracted_data, columns=cols)\n",
        "\n",
        "df_v1 = df[df['num_v1_neurons'] > 0]\n",
        "df_v1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mouse_name</th>\n",
              "      <th>num_v1_neurons</th>\n",
              "      <th>num_neurons</th>\n",
              "      <th>num_trials</th>\n",
              "      <th>num_time_bins</th>\n",
              "      <th>spike_times</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cori</td>\n",
              "      <td>178</td>\n",
              "      <td>734</td>\n",
              "      <td>214</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cori</td>\n",
              "      <td>114</td>\n",
              "      <td>619</td>\n",
              "      <td>228</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Forssmann</td>\n",
              "      <td>39</td>\n",
              "      <td>1769</td>\n",
              "      <td>249</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 10.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Hench</td>\n",
              "      <td>48</td>\n",
              "      <td>1156</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Hench</td>\n",
              "      <td>105</td>\n",
              "      <td>1172</td>\n",
              "      <td>447</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Lederberg</td>\n",
              "      <td>66</td>\n",
              "      <td>698</td>\n",
              "      <td>340</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Lederberg</td>\n",
              "      <td>42</td>\n",
              "      <td>756</td>\n",
              "      <td>268</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Moniz</td>\n",
              "      <td>122</td>\n",
              "      <td>899</td>\n",
              "      <td>235</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Muller</td>\n",
              "      <td>133</td>\n",
              "      <td>646</td>\n",
              "      <td>444</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Radnitz</td>\n",
              "      <td>94</td>\n",
              "      <td>885</td>\n",
              "      <td>261</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Radnitz</td>\n",
              "      <td>162</td>\n",
              "      <td>1056</td>\n",
              "      <td>178</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Theiler</td>\n",
              "      <td>15</td>\n",
              "      <td>1348</td>\n",
              "      <td>343</td>\n",
              "      <td>250</td>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mouse_name  ...                                        spike_times\n",
              "0        Cori  ...  [[[0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0....\n",
              "2        Cori  ...  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "3   Forssmann  ...  [[[0.0, 10.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0...\n",
              "7       Hench  ...  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "9       Hench  ...  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "11  Lederberg  ...  [[[0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....\n",
              "13  Lederberg  ...  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "19      Moniz  ...  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "21     Muller  ...  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "24    Radnitz  ...  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "25    Radnitz  ...  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "38    Theiler  ...  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "\n",
              "[12 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq2bkTXbxj_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Dif model -- achieves class likelihood\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "my_mouse             = extracted_data[0]\n",
        "feedback             = my_mouse['binary_feedback']\n",
        "spikes_my_mouse      = my_mouse['spikes_reordered']\n",
        "neurons, __, __,     = np.shape(spikes_my_mouse)\n",
        "neurons              = [neuron for neuron in range(neurons)]\n",
        "\n",
        "## assuming L2 > L1 as vector already sparse\n",
        "\n",
        "all_accuracies  = []\n",
        "neuron2accuracy = {}\n",
        "\n",
        "for neuron in neurons:\n",
        "  X         = spikes_my_mouse[neuron][1:][:]\n",
        "  y         = feedback[:-1]\n",
        "  \n",
        "\n",
        "  \"\"\" Balance classifiers\n",
        "  \"\"\"\n",
        "  zeros     = len(y[y == 0])\n",
        "  mask      = np.argsort(y)\n",
        "  slice_arr = mask[:(2 * zeros)]\n",
        "  slice_arr = np.sort(slice_arr)\n",
        "  X         = X[slice_arr]\n",
        "  y         = y[slice_arr]\n",
        "  \"\"\" End balance classifiers\n",
        "  \"\"\"\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqABvwYomfQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "f0117afe-4b1e-423e-b24c-f4c740ba0975"
      },
      "source": [
        "#@ logistic regression\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "my_mouse             = extracted_data[11]\n",
        "feedback             = my_mouse['binary_feedback']\n",
        "spikes_my_mouse      = my_mouse['spikes_reordered']\n",
        "#neurons, trials, bins, = np.shape(spikes_my_mouse)\n",
        "neurons, trials, bins, = np.shape(spikes_my_mouse[:,:,50:150])\n",
        "\n",
        "LDR = np.zeros([trials, neurons])\n",
        "for t in range(trials):\n",
        "    for n in range(neurons):\n",
        "      spike_counts= sum(spikes_my_mouse[n][t])\n",
        "      LDR[t,n] = spike_counts\n",
        "\n",
        "#split training-test data\n",
        "num_trials_in_training = int(np.round(trials * 0.8))\n",
        "training_data = LDR[range(num_trials_in_training), :]\n",
        "test_data = LDR[range(num_trials_in_training, trials), : ]\n",
        "training_feedback = feedback[range(num_trials_in_training)]\n",
        "test_feedback = feedback[range(num_trials_in_training, trials)]\n",
        "\n",
        "# define model\n",
        "log_reg = LogisticRegression(penalty=\"none\")\n",
        "\n",
        "# fit model to data\n",
        "log_reg.fit(training_data, training_feedback)\n",
        "#test data\n",
        "def compute_accuracy(X, y, model):\n",
        "  y_pred = model.predict(X)\n",
        "  accuracy = (y == y_pred).mean()\n",
        "  return accuracy\n",
        "\n",
        "test_accuracy = compute_accuracy(test_data, test_feedback, log_reg)\n",
        "print(f\"Accuracy on the testing data: {test_accuracy:.2%}\")\n",
        "\n",
        "#cross validation accuracy\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(LogisticRegression(), LDR, feedback, cv=5)\n",
        "if not np.isnan(accuracies).any():\n",
        "  mean_accuracy           = accuracies.mean()\n",
        "  print(f\"Cross-validated Accuracy: {mean_accuracy:.2%}\")\n",
        "  "
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on the testing data: 72.06%\n",
            "Cross-validated Accuracy: 60.88%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}